# classifying_time_signature_in-music



## About

 
--With the advent of neural nets, the idea that a computer has the ability to find patterns within data hasn't been proven more. Through the --use of many convulutional layers, deep learning unlocks puzzles which are too complex for us humans.

The goal of this project is to use machine learning to find temporal patterns in music which give it its structure in time, namely, the time signature. --We are all familiar with the natural impulse of tapping along while vibing to a good song, --

“The aim of a beat tracker is to recover a sequence of time instants from a musical input that are consistent with the times when a human might tap their foot. Beyond an exercise in modelling a human response to a musical stimulus, beat tracking can be used in many applications including musical interaction systems, content-based audio effects, and increasingly as a meaningful temporal segmentation for higher level MIR tasks such as chord extraction, structural segmentation of audio  and music similarity.” 

### Goal etc..



### Some fundamental terminology



## Data 

### collection (and usage)

### Exploring

### Feature Engineering


#### Exlplaining spectrograms etc..





## Modeling


### what?





## Permissions & Licenses

Thank you